{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91909513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\91700\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\91700\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\91700\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: gradio in c:\\users\\91700\\lib\\site-packages (5.34.2)\n",
      "Requirement already satisfied: ollama in c:\\users\\91700\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\91700\\lib\\site-packages (from pandas) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\91700\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\91700\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\91700\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\91700\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\91700\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\91700\\lib\\site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\91700\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\91700\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\91700\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\91700\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\91700\\lib\\site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\91700\\lib\\site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: audioop-lts<1.0 in c:\\users\\91700\\lib\\site-packages (from gradio) (0.2.1)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\91700\\lib\\site-packages (from gradio) (0.115.13)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\91700\\lib\\site-packages (from gradio) (0.6.0)\n",
      "Requirement already satisfied: gradio-client==1.10.3 in c:\\users\\91700\\lib\\site-packages (from gradio) (1.10.3)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\91700\\lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\91700\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\91700\\lib\\site-packages (from gradio) (0.33.0)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\91700\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\91700\\lib\\site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\91700\\lib\\site-packages (from gradio) (3.10.18)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\91700\\lib\\site-packages (from gradio) (2.11.7)\n",
      "Requirement already satisfied: pydub in c:\\users\\91700\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\91700\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\91700\\lib\\site-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\91700\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\91700\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\91700\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\91700\\lib\\site-packages (from gradio) (0.46.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\91700\\lib\\site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\91700\\lib\\site-packages (from gradio) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\91700\\lib\\site-packages (from gradio) (4.14.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\91700\\lib\\site-packages (from gradio) (0.34.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\91700\\lib\\site-packages (from gradio-client==1.10.3->gradio) (2025.5.1)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\users\\91700\\lib\\site-packages (from gradio-client==1.10.3->gradio) (15.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\91700\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\91700\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\91700\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\91700\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\91700\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\91700\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\91700\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\91700\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\91700\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\91700\\lib\\site-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\91700\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\91700\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\91700\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
      "Requirement already satisfied: requests in c:\\users\\91700\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\91700\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\91700\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\91700\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\91700\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\91700\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\91700\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\91700\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas seaborn matplotlib gradio ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52938e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url=r\"C:\\Users\\91700\\Downloads\\titanic.csv\"\n",
    "df=pd.read_csv(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3df38c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4090963a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_insights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Generate AI Insights\u001b[39;00m\n\u001b[32m      7\u001b[39m summary = df.describe().to_string()\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m insights = \u001b[43mgenerate_insights\u001b[49m(summary)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ”¹ AI-Generated Insights:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, insights)\n",
      "\u001b[31mNameError\u001b[39m: name 'generate_insights' is not defined"
     ]
    }
   ],
   "source": [
    "def genarate_insights(df_summary):\n",
    "    prompt=f\"Analyze the dataset summary and provide insights:\\n\\n{df_summary}\"\n",
    "    response=ollama.chat(model=\"misttral\",messages=[{\"role\":\"user\",\"content\":prompt}])\n",
    "    return response['message']\n",
    "\n",
    "# Generate AI Insights\n",
    "summary = df.describe().to_string()\n",
    "insights = generate_insights(summary)\n",
    "print(\"\\nðŸ”¹ AI-Generated Insights:\\n\", insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a4dad3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://4949065b83edd48dc4.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4949065b83edd48dc4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\blocks.py\", line 2220, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\blocks.py\", line 1731, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        fn, *processed_input, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\utils.py\", line 904, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\91700\\AppData\\Local\\Temp\\ipykernel_20896\\2263510978.py\", line 4, in eda_analysis\n",
      "    df=pd.read_csv(file.name)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "                   ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1898, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\", line 93, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "                   ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "  File \"pandas/_libs/parsers.pyx\", line 574, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 663, in pandas._libs.parsers.TextReader._get_header\n",
      "  File \"pandas/_libs/parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"pandas/_libs/parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"pandas/_libs/parsers.pyx\", line 2053, in pandas._libs.parsers.raise_parser_error\n",
      "  File \"<frozen codecs>\", line 325, in decode\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\blocks.py\", line 2220, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\blocks.py\", line 1731, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        fn, *processed_input, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\utils.py\", line 904, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\91700\\AppData\\Local\\Temp\\ipykernel_20896\\2263510978.py\", line 4, in eda_analysis\n",
      "    df=pd.read_csv(file.name)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "                   ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1898, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\", line 93, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "                   ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "  File \"pandas/_libs/parsers.pyx\", line 574, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 663, in pandas._libs.parsers.TextReader._get_header\n",
      "  File \"pandas/_libs/parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"pandas/_libs/parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"pandas/_libs/parsers.pyx\", line 2053, in pandas._libs.parsers.raise_parser_error\n",
      "  File \"<frozen codecs>\", line 325, in decode\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\blocks.py\", line 2220, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\blocks.py\", line 1731, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        fn, *processed_input, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\utils.py\", line 904, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\91700\\AppData\\Local\\Temp\\ipykernel_20896\\2263510978.py\", line 4, in eda_analysis\n",
      "    df=pd.read_csv(file.name)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "                   ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1898, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\", line 93, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "                   ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "  File \"pandas/_libs/parsers.pyx\", line 574, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 663, in pandas._libs.parsers.TextReader._get_header\n",
      "  File \"pandas/_libs/parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"pandas/_libs/parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"pandas/_libs/parsers.pyx\", line 2053, in pandas._libs.parsers.raise_parser_error\n",
      "  File \"<frozen codecs>\", line 325, in decode\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\blocks.py\", line 2220, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\blocks.py\", line 1731, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        fn, *processed_input, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\utils.py\", line 904, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\91700\\AppData\\Local\\Temp\\ipykernel_20896\\2263510978.py\", line 5, in eda_analysis\n",
      "    summary=df.describe().tostring()\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6318, in __getattr__\n",
      "    return object.__getattribute__(self, name)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "AttributeError: 'DataFrame' object has no attribute 'tostring'. Did you mean: 'to_string'?\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\blocks.py\", line 2220, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\blocks.py\", line 1731, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        fn, *processed_input, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\utils.py\", line 904, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\91700\\AppData\\Local\\Temp\\ipykernel_20896\\2263510978.py\", line 4, in eda_analysis\n",
      "    df=pd.read_csv(file.name)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "                   ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1898, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\", line 93, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "                   ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "  File \"pandas/_libs/parsers.pyx\", line 574, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 663, in pandas._libs.parsers.TextReader._get_header\n",
      "  File \"pandas/_libs/parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"pandas/_libs/parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"pandas/_libs/parsers.pyx\", line 2053, in pandas._libs.parsers.raise_parser_error\n",
      "  File \"<frozen codecs>\", line 325, in decode\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x9c in position 146: invalid start byte\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset file at: .gradio\\flagged\\dataset1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\blocks.py\", line 2220, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\blocks.py\", line 1731, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        fn, *processed_input, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\utils.py\", line 904, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\91700\\AppData\\Local\\Temp\\ipykernel_20896\\2263510978.py\", line 4, in eda_analysis\n",
      "    df=pd.read_csv(file.name)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "                   ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1898, in _make_engine\n",
      "    return mapping[engine](f, **self.options)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\", line 93, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "                   ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
      "  File \"pandas/_libs/parsers.pyx\", line 574, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 663, in pandas._libs.parsers.TextReader._get_header\n",
      "  File \"pandas/_libs/parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"pandas/_libs/parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"pandas/_libs/parsers.pyx\", line 2053, in pandas._libs.parsers.raise_parser_error\n",
      "  File \"<frozen codecs>\", line 325, in decode\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 176: invalid start byte\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def eda_analysis(file):\n",
    "    df=pd.read_csv(file.name)\n",
    "    summary=df.describe().tostring()\n",
    "    insights= generate_insights(summary)\n",
    "    return insights\n",
    "\n",
    "demo=gr.Interface(fn=eda_analysis, inputs=\"file\", outputs=\"text\", title=\"AI-Powered EDA with Mistral\")\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99da369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* Running on public URL: https://b7edc294aae3ef4cfb.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://b7edc294aae3ef4cfb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91700\\AppData\\Local\\Temp\\ipykernel_20896\\1301349539.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\91700\\AppData\\Local\\Temp\\ipykernel_20896\\1301349539.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\91700\\AppData\\Local\\Temp\\ipykernel_20896\\1301349539.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\91700\\AppData\\Local\\Temp\\ipykernel_20896\\1301349539.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\91700\\AppData\\Local\\Temp\\ipykernel_20896\\1301349539.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\91700\\AppData\\Local\\Temp\\ipykernel_20896\\1301349539.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\91700\\AppData\\Local\\Temp\\ipykernel_20896\\1301349539.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\91700\\AppData\\Local\\Temp\\ipykernel_20896\\1301349539.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\blocks.py\", line 2220, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\blocks.py\", line 1731, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        fn, *processed_input, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\gradio\\utils.py\", line 904, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\91700\\AppData\\Local\\Temp\\ipykernel_20896\\1301349539.py\", line 26, in eda_analysis\n",
      "    insights = generate_ai_insights(summary)\n",
      "  File \"C:\\Users\\91700\\AppData\\Local\\Temp\\ipykernel_20896\\1301349539.py\", line 36, in generate_ai_insights\n",
      "    response = ollama.chat(model=\"mistral\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\ollama\\_client.py\", line 342, in chat\n",
      "    return self._request(\n",
      "           ~~~~~~~~~~~~~^\n",
      "      ChatResponse,\n",
      "      ^^^^^^^^^^^^^\n",
      "    ...<12 lines>...\n",
      "      stream=stream,\n",
      "      ^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\ollama\\_client.py\", line 180, in _request\n",
      "    return cls(**self._request_raw(*args, **kwargs).json())\n",
      "                 ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\91700\\Lib\\site-packages\\ollama\\_client.py\", line 124, in _request_raw\n",
      "    raise ResponseError(e.response.text, e.response.status_code) from None\n",
      "ollama._types.ResponseError: model requires more system memory (5.5 GiB) than is available (4.3 GiB) (status code: 500)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ollama\n",
    "\n",
    "# Function to Perform EDA and Generate Visualizations\n",
    "def eda_analysis(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "   \n",
    "    # Fill missing values with median for numeric columns\n",
    "    for col in df.select_dtypes(include=['number']).columns:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "   \n",
    "    # Fill missing values with mode for categorical columns\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "   \n",
    "    # Data Summary\n",
    "    summary = df.describe(include='all').to_string()\n",
    "   \n",
    "    # Missing Values\n",
    "    missing_values = df.isnull().sum().to_string()\n",
    "\n",
    "    # Generate AI Insights\n",
    "    insights = generate_ai_insights(summary)\n",
    "   \n",
    "    # Generate Data Visualizations\n",
    "    plot_paths = generate_visualizations(df)\n",
    "   \n",
    "    return f\"\\n Data Loaded Successfully!\\n\\n Summary:\\n{summary}\\n\\n Missing Values:\\n{missing_values}\\n\\n AI Insights:\\n{insights}\", plot_paths\n",
    "\n",
    "# AI-Powered Insights using Mistral-7B (Ollama)\n",
    "def generate_ai_insights(df_summary):\n",
    "    prompt = f\"Analyze the dataset summary and provide insights:\\n\\n{df_summary}\"\n",
    "    response = ollama.chat(model=\"mistral\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response['message']['content']\n",
    "\n",
    "# Function to Generate Data Visualizations\n",
    "def generate_visualizations(df):\n",
    "    plot_paths = []\n",
    "   \n",
    "    # Histograms for Numeric Columns\n",
    "    for col in df.select_dtypes(include=['number']).columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.histplot(df[col], bins=30, kde=True, color=\"blue\")\n",
    "        plt.title(f\"Distribution of {col}\")\n",
    "        path = f\"{col}_distribution.png\"\n",
    "        plt.savefig(path)\n",
    "        plot_paths.append(path)\n",
    "        plt.close()\n",
    "   \n",
    "    # Correlation Heatmap (only numeric columns)\n",
    "    numeric_df = df.select_dtypes(include=['number'])\n",
    "    if not numeric_df.empty:\n",
    "        plt.figure(figsize=(8,5))\n",
    "        sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "        plt.title(\"Correlation Heatmap\")\n",
    "        path = \"correlation_heatmap.png\"\n",
    "        plt.savefig(path)\n",
    "        plot_paths.append(path)\n",
    "        plt.close()\n",
    "\n",
    "    return plot_paths\n",
    "\n",
    "# Gradio Interface\n",
    "demo = gr.Interface(\n",
    "    fn=eda_analysis,\n",
    "    inputs=gr.File(type=\"filepath\"),\n",
    "    outputs=[gr.Textbox(label=\"EDA Report\"), gr.Gallery(label=\"Data Visualizations\")],\n",
    "    title=\"ðŸ“Š LLM-Powered Exploratory Data Analysis (EDA)\",\n",
    "    description=\"Upload any dataset CSV file and get automated EDA insights with AI-powered analysis and visualizations.\"\n",
    ")\n",
    "\n",
    "# Launch the Gradio App\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05f8229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
